name: Update Stats in README

on:
  push:
    branches:
      - main
    paths:
      - 'data/stats.json'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-readme:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check if stats.json exists
        id: check_stats
        run: |
          if [ -f "data/stats.json" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "âš ï¸  data/stats.json not found, skipping update"
          fi

      - name: Generate stats table
        if: steps.check_stats.outputs.exists == 'true'
        run: |
          cat > generate_stats.py << 'EOF'
          import json
          import os
          from datetime import datetime, timezone

          # Read stats.json
          with open('data/stats.json', 'r') as f:
              stats = json.load(f)

          # Generate markdown table
          table = []
          table.append("## ðŸ“Š Blocklist Statistics\n")
          table.append("| URL | Domains | Status | Success | Failures | Last Checked |")
          table.append("|-----|---------|--------|---------|----------|--------------|")

          # Sort by domain count (descending)
          sorted_stats = sorted(stats.items(), key=lambda x: x[1].get('total_domains', 0), reverse=True)

          for url, data in sorted_stats:
              # Truncate URL if too long
              display_url = url if len(url) <= 50 else url[:47] + "..."

              # Format domains
              domains = data.get('total_domains', 0)
              if domains >= 1000000:
                  domains_str = f"{domains/1000000:.1f}M"
              elif domains >= 1000:
                  domains_str = f"{domains/1000:.1f}K"
              else:
                  domains_str = str(domains)

              # Status
              is_blacklisted = data.get('blacklisted', False)
              failures = data.get('failure_count', 0)
              if is_blacklisted or failures >= 3:
                  status = "âŒ Filtered"
              else:
                  status = "âœ… Active"

              # Success/failures
              success = data.get('success_count', 0)

              # Last checked
              last_checked = data.get('last_checked', '')
              if last_checked:
                  try:
                      dt = datetime.fromisoformat(last_checked.replace('Z', '+00:00'))
                      now = datetime.now(timezone.utc)
                      delta = now - dt

                      if delta.days > 0:
                          last_str = f"{delta.days}d ago"
                      elif delta.seconds >= 3600:
                          last_str = f"{delta.seconds // 3600}h ago"
                      elif delta.seconds >= 60:
                          last_str = f"{delta.seconds // 60}m ago"
                      else:
                          last_str = "just now"
                  except:
                      last_str = "unknown"
              else:
                  last_str = "never"

              table.append(f"| {display_url} | {domains_str} | {status} | {success} | {failures} | {last_str} |")

          # Summary
          total_urls = len(stats)
          active = sum(1 for s in stats.values() if not s.get('blacklisted', False) and s.get('failure_count', 0) < 3)
          filtered = total_urls - active
          total_domains = sum(s.get('total_domains', 0) for s in stats.values() if s.get('success_count', 0) > 0)

          if total_domains >= 1000000:
              total_str = f"{total_domains/1000000:.1f}M"
          elif total_domains >= 1000:
              total_str = f"{total_domains/1000:.1f}K"
          else:
              total_str = str(total_domains)

          table.append("")
          table.append(f"**Summary:** {total_urls} total URLs | {active} active | {filtered} filtered | ~{total_str} total domains")
          table.append(f"\n*Last updated: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')}*\n")

          # Write to file
          with open('stats_table.md', 'w') as f:
              f.write('\n'.join(table))
          EOF

          python3 generate_stats.py

      - name: Update README
        if: steps.check_stats.outputs.exists == 'true'
        run: |
          # Check if stats section exists in README
          if grep -q "## ðŸ“Š Blocklist Statistics" README.md; then
            # Remove old stats section
            sed -i '/## ðŸ“Š Blocklist Statistics/,/^\*Last updated:/d' README.md
          fi

          # Append new stats to end of README
          cat stats_table.md >> README.md

          echo "âœ… README updated with latest stats"

      - name: Commit and push if changed
        if: steps.check_stats.outputs.exists == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          if git diff --quiet README.md; then
            echo "No changes to commit"
          else
            git add README.md
            git commit -m "ðŸ“Š Auto-update blocklist statistics"
            git push
            echo "âœ… Changes pushed to repository"
          fi
